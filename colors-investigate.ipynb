{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pragmatic color descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Shubham Chowdhary\"\n",
    "__version__ = \"Original System, XCS224u\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colors import ColorsCorpusReader\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_color_describer import ContextualColorDescriber\n",
    "from torch_color_describer import create_example_dataset\n",
    "\n",
    "import utils\n",
    "from utils import START_SYMBOL, END_SYMBOL, UNK_SYMBOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.fix_random_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS_SRC_FILENAME = os.path.join(\n",
    "    \"data\", \"colors\", \"filteredCorpus.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All two-word examples as a dev corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#DONE(schowdhary): Use 2-word datasets for fast experimental testing of the model architecture until you find good scoring models. Please remember to use full dataset train/dev split on the final pipeline you choose to proceed with."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_corpus = ColorsCorpusReader(\n",
    "    COLORS_SRC_FILENAME,\n",
    "    word_count=2,\n",
    "    normalize_colors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_examples = list(dev_corpus.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This subset has about one-third the examples of the full corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "13890"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dev dataset\n",
    "\n",
    "The first step is to extract the raw color and raw texts from the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "dev_rawcols, dev_texts = zip(*[[ex.colors, ex.contents] for ex in dev_examples])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Random train–test split for development\n",
    "\n",
    "For the sake of development runs, we create a random train–test split:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "dev_rawcols_train, dev_rawcols_test, dev_texts_train, dev_texts_test = \\\n",
    "    train_test_split(dev_rawcols, dev_texts)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### We try following tokenization techniques\n",
    "\n",
    "1. Lowering the case and space splitting the content, maybe sentiment splitting can be tried?\n",
    "2. Generating vocab only from the training examples and then replacing all the solo occurrences with \\<UNK\\> in train and dev/test set."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "\n",
    "    def basic_tokenize(s):\n",
    "        # Improved on punctuation splitting by using the TweetTokenizer below\n",
    "        return [START_SYMBOL] + s.lower().split() + [END_SYMBOL]\n",
    "\n",
    "    from nltk.tokenize import TweetTokenizer\n",
    "    sentiment_tknzr = TweetTokenizer(preserve_case=False)\n",
    "\n",
    "    def tweet_tokenize(s):\n",
    "        return [START_SYMBOL] + sentiment_tknzr.tokenize(s) + [END_SYMBOL]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    from collections import Counter\n",
    "    # Since we are using a small dataset for now, we will create a vocab using that. We will reuse this pipeline later-on when we reiterate this process for full dataset\n",
    "    def create_vocab_from_content_dataset(train_texts, lowest_allowed_freq, tokenizer):\n",
    "        \"\"\"\n",
    "        This routine creates vocab from the content dataset passed to it by converting all text to lower-case. As a safely measure, it also returns a lower-cased space split copy of dataset. Please use that version of dataset for further training in the pipeline.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_texts : list\n",
    "            list of utterances from training set\n",
    "\n",
    "        lowest_allowed_freq : int\n",
    "            least frequency for the words that should be the part of vocab\n",
    "\n",
    "        tokenizer : func(str)->list of str\n",
    "            tokenizer that splits a text to a list of tokens\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            training vocab list\n",
    "        list of list\n",
    "            list of transformed word sequences\n",
    "        list\n",
    "            list of words with very few occurrences that are removed from training transformed word sequences. Should be removed from dev/test set too during preprocessing\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        train_word_seqs = [tokenizer(text) for text in train_texts]\n",
    "        train_words_list = [word for word_seq in train_word_seqs for word in word_seq]\n",
    "\n",
    "        ctr_train_words_list = Counter(train_words_list)\n",
    "        banned_words = [k for (k, v) in ctr_train_words_list.most_common() if v < lowest_allowed_freq]\n",
    "\n",
    "        train_words_vocab = sorted(set(train_words_list) - set(banned_words))\n",
    "        train_words_vocab += [UNK_SYMBOL]\n",
    "\n",
    "        filled_train_word_seqs = [[word if word not in banned_words else UNK_SYMBOL for word in word_seq] for word_seq in train_word_seqs]\n",
    "\n",
    "        return train_words_vocab, filled_train_word_seqs, banned_words\n",
    "\n",
    "    def transform_test_content(test_texts, train_vocab, tokenizer):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        test_texts : list\n",
    "            list of utturances from test/dev set\n",
    "\n",
    "        train_vocab : list\n",
    "            list of vocab words that was formed using the training set\n",
    "\n",
    "        tokenizer : func(str)->list of str\n",
    "            tokenizer that splits a string text to list of string tokens\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "         list of list\n",
    "            trainable list of word sequences\n",
    "\n",
    "        \"\"\"\n",
    "        test_word_seqs = [tokenizer(text) for text in test_texts]\n",
    "        filled_test_word_seqs = [[word if word in train_vocab else UNK_SYMBOL for word in word_seq] for word_seq in test_word_seqs]\n",
    "\n",
    "        return filled_test_word_seqs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    # DONE(schowdhary): see behaviour with lowest_allowed_freq=2 (& 1 also) in the bigger dataset.\n",
    "    # There was not much difference. Just that with a smaller vocab we can get similar accuracy scores\n",
    "    dev_train_vocab, filled_dev_train_word_seqs, dev_train_removed_words = create_vocab_from_content_dataset(train_texts=dev_texts_train, lowest_allowed_freq=1, tokenizer=tweet_tokenize)\n",
    "\n",
    "    print(len(dev_train_removed_words), \" these many words were removed from the train vocab\")\n",
    "    print(\"Size of train set vocab, \", len(dev_train_vocab))\n",
    "    print(\"Banned words:\\n\", dev_train_removed_words)\n",
    "    print(\"A sample tokenized train text:\\n\", filled_dev_train_word_seqs[360])\n",
    "    print(\"And the actual text was:\\n\", dev_texts_train[360])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "When we used simple space splits and excluded words with freq < 2, a lot of combined color words got excluded. So we decided to split even on punctuations to be sure that we include more color words. As can be seen, we still are discarding approx 50% words from the train set full vocab to \\<UNK\\> if we remove words with freq < 2. Some are typo words but some of these are real words that, though rare, give real sense for colors. Hence, we decide not to remove freq=1 words from the train_vocab for now. **_This also calls for the need to use subword tokenizers like the BERT_**."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    def tokenize_example_on_vocab(s, train_vocab, tokenizer):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        s : str\n",
    "            string text\n",
    "        train_vocab : list\n",
    "            list of supported words from training dataset\n",
    "        tokenizer : func(str)-> list of str\n",
    "            tokenizer function that takes string converts it into list of tokens\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            list of words in a tokenized format\n",
    "        \"\"\"\n",
    "        tokens_s = tokenizer(s)\n",
    "        filled_word_seq = [word if word in train_vocab else UNK_SYMBOL for word in tokens_s]\n",
    "\n",
    "        return filled_word_seq"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def tokenize_example(s):\n",
    "    if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "        return tokenize_example_on_vocab(s, train_vocab=dev_train_vocab, tokenizer=tweet_tokenize)\n",
    "    else:\n",
    "        return [START_SYMBOL] + s.lower().split() + [END_SYMBOL]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    print(\"Tokenized text:\")\n",
    "    print(tokenize_example(dev_texts_train[376]))\n",
    "    print(\"Actual text:\")\n",
    "    print(dev_texts_train[376])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Use the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "dev_seqs_train = [tokenize_example(s) for s in dev_texts_train]\n",
    "\n",
    "dev_seqs_test = [tokenize_example(s) for s in dev_texts_test]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We use only the train set to derive a vocabulary for the model:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "dev_vocab = sorted({w for toks in dev_seqs_train for w in toks})\n",
    "\n",
    "dev_vocab += [UNK_SYMBOL]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dev_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1050"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    import cmath\n",
    "    from itertools import product\n",
    "\n",
    "# Based on Monroe et. al. 2016\n",
    "def represent_color_context(colors):\n",
    "    # return [color for color in colors]\n",
    "    return [represent_color(color) for color in colors]\n",
    "\n",
    "def represent_color(color):\n",
    "\n",
    "    if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "        # the color loaded from the dataset here is a 3-d vector (HLS) with range (0-1, 0-1, 0-1) that was scaled from (0-360, 0-100, 0-100)\n",
    "\n",
    "        # HLS to HVS\n",
    "        actual_hue = 360 * color[0]\n",
    "        l = color[1]\n",
    "        s_l = color[2]\n",
    "\n",
    "        v = l + s_l * min(l, 1-l)\n",
    "        s_v = 0. if v == 0 else 2 * (1 - (l/v))\n",
    "\n",
    "        # hvs_color is in range (0-360, 0-1, 0-1)\n",
    "\n",
    "        # HVS to fourier representation\n",
    "        # Monroe et. al. (2016) requires (h, s, v) in (0-360, 0-200, 0-200)\n",
    "        # which is then normalized as (h/360, s/200, v/200).\n",
    "        # So the fourier transformation requires them in the range (h, s, v) ~ (0-1, 0-1, 0-1)\n",
    "\n",
    "        f_real = []\n",
    "        f_imag = []\n",
    "\n",
    "        # collect the values across the cross-product of axes\n",
    "        for j, k, l in product((0, 1, 2), repeat = 3):\n",
    "            f_hat_jkl = cmath.rect(1, (-2 * cmath.pi * (j * (actual_hue/360.0) + k * s_v + l * v)))\n",
    "            f_real.append(f_hat_jkl.real)\n",
    "            f_imag.append(f_hat_jkl.imag)\n",
    "\n",
    "        f_color = f_real + f_imag\n",
    "\n",
    "        return f_color\n",
    "\n",
    "    else:\n",
    "        return color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(represent_color_context(dev_rawcols_train[0]))\n",
    "\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    res = represent_color_context(dev_rawcols_train[370])\n",
    "    print(\"Color representation raw:\\n\", dev_rawcols_train[370])\n",
    "    print(\"Length of one color's dimension:\\n\", len(res[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Use the color representer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "dev_cols_train = [represent_color_context(colors) for colors in dev_rawcols_train]\n",
    "\n",
    "dev_cols_test = [represent_color_context(colors) for colors in dev_rawcols_test]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "At this point, our preprocessing steps are complete, and we can fit a first model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "dev_mod = ContextualColorDescriber(\n",
    "    dev_vocab,\n",
    "    early_stopping=True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    %time _ = dev_mod.fit(dev_cols_train, dev_seqs_train)\n",
    "else:\n",
    "    dev_mod.fit(dev_cols_train, dev_seqs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 107. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 39.15624952316284"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 2s\n"
     ]
    }
   ],
   "source": [
    "evaluation = dev_mod.evaluate(dev_cols_test, dev_seqs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['listener_accuracy', 'corpus_bleu', 'target_index', 'predicted_index', 'predicted_utterance'])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation['listener_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.7926864382378347"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_mod.listener_accuracy(dev_cols_test, dev_seqs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.7926864382378347"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation['corpus_bleu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.6637952127945157"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu, predicted_utterances = dev_mod.corpus_bleu(dev_cols_test, dev_seqs_test)\n",
    "\n",
    "bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.6637952127945157"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation['target_index'][: 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[2, 2, 2, 2, 2]"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation['predicted_index'][: 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[0, 2, 2, 0, 2]"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation['predicted_utterance'][: 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can also see the model's predicted sequences given color context inputs:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "dev_mod.predict(dev_cols_test[: 1])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[['<s>', 'bright', 'purple', '</s>']]"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_seqs_test[: 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**_Evaluating fourier color representations,_**\n",
    "For normalized HSL values, the result: **_Error: 52.733 (unstable perplexity calculations), listener_accuracy: 0.3852, bleu: 0.4948_**\n",
    "For fourier transformed HSV-HSL values, the result: **_Error: 39.156, listener_accuracy: 0.79268, blue: 0.66379_**\n",
    "\n",
    "**_As we can see, the fourier transformation really improves the learning._**"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GloVe embeddings\n",
    "\n",
    "The above model uses a random initial embedding, as configured by the decoder used by `ContextualColorDescriber`. Lets instead try using GloVe inputs.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "GLOVE_HOME = os.path.join('data', 'glove.6B')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_glove_embedding(vocab, glove_base_filename='glove.6B.50d.txt'):\n",
    "\n",
    "    glove_lookup = utils.glove2dict(\n",
    "        os.path.join(GLOVE_HOME, glove_base_filename))\n",
    "\n",
    "    glove_embedding, glove_vocab = utils.create_pretrained_embedding(\n",
    "            glove_lookup, vocab)\n",
    "\n",
    "    return glove_embedding, glove_vocab\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Try the GloVe representations"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# TODO(schowdhary): Try character level tokenization and representations"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see if GloVe helped for our development data:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "dev_glove_embedding, dev_glove_vocab = create_glove_embedding(dev_vocab)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dev_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1050"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_glove_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1050"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_mod_glove = ContextualColorDescriber(\n",
    "    dev_glove_vocab,\n",
    "    embedding=dev_glove_embedding,\n",
    "    early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = dev_mod_glove.fit(dev_cols_train, dev_seqs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 93. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 40.069143533706665"
     ]
    }
   ],
   "source": [
    "dev_mod_glove.listener_accuracy(dev_cols_test, dev_seqs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.788367405701123"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# further evaluating the GloVe embedding-based model\n",
    "\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    dev_glove_embedding, dev_glove_vocab = create_glove_embedding(dev_vocab, glove_base_filename='glove.6B.50d.txt')\n",
    "\n",
    "    print(\"Total vocab size before:\\n\", len(dev_vocab))\n",
    "    print(\"Vocab size for GloVe embeddings:\\n\", len(dev_glove_vocab))\n",
    "\n",
    "    custom_dev_mod_glove = ContextualColorDescriber(\n",
    "        dev_glove_vocab,\n",
    "        embedding=dev_glove_embedding,\n",
    "        early_stopping=True)\n",
    "\n",
    "    _ = custom_dev_mod_glove.fit(dev_cols_train, dev_seqs_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vocab size before:\n",
      " 1050\n",
      "Vocab size for GloVe embeddings:\n",
      " 1050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 114. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 36.531978368759155"
     ]
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    print(custom_dev_mod_glove.listener_accuracy(dev_cols_test, dev_seqs_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**_GloVe 50d, 100d embeddings work fine with accuracy ~ 0.7877_**\n",
    "Error goes down further with 200d upto 32.58, but test accuracy does not improve. This suggests no significant learning."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Already learnt representations (from word-relatedness research work)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "\n",
    "    VSM_HOME = os.path.join('data', 'vsmdata')\n",
    "\n",
    "    def create_df_vsm():\n",
    "        full_matrix_df = pd.read_csv(os.path.join(VSM_HOME, \"best_devset_word_repr_vsm.csv.gz\"), index_col=0)\n",
    "        return full_matrix_df\n",
    "\n",
    "    custom_vsm = create_df_vsm()\n",
    "\n",
    "    custom_vsm_lookup = {word:custom_vsm.loc[word] for word in custom_vsm.index}\n",
    "\n",
    "    print(custom_vsm_lookup[\"water\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.007726\n",
      "1      -0.002936\n",
      "2       0.001923\n",
      "3      -0.002022\n",
      "4       0.029006\n",
      "          ...   \n",
      "1275    0.009053\n",
      "1276   -0.020875\n",
      "1277    0.027672\n",
      "1278    0.033489\n",
      "1279    0.011569\n",
      "Name: water, Length: 1280, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    custom_vsm_embedding, custom_vsm_vocab = utils.create_pretrained_embedding(\n",
    "            custom_vsm_lookup, dev_vocab)\n",
    "\n",
    "    print(\"Total vocab size before:\\n\", len(dev_vocab))\n",
    "    print(\"Vocab size for Custom word-relatedness VSM embeddings:\\n\", len(custom_vsm_vocab))\n",
    "\n",
    "    custom_vsm_dev_mod = ContextualColorDescriber(\n",
    "        custom_vsm_vocab,\n",
    "        embedding=custom_vsm_embedding,\n",
    "        early_stopping=True)\n",
    "\n",
    "    _ = custom_vsm_dev_mod.fit(dev_cols_train, dev_seqs_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vocab size before:\n",
      " 1050\n",
      "Vocab size for Custom word-relatedness VSM embeddings:\n",
      " 1050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 15. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 52.26255178451538"
     ]
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    print(custom_vsm_dev_mod.listener_accuracy(dev_cols_test, dev_seqs_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**_Not a promissing performace._**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Color-Input Describer (as used by Monroe et. al.)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_color_describer import Decoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ColorContextDecoder(Decoder):\n",
    "    def __init__(self, color_dim, *args, **kwargs):\n",
    "        self.color_dim = color_dim\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=self.embed_dim + self.color_dim, # -> embed_dim + c (from get_embeddings below)\n",
    "            hidden_size=self.hidden_dim,\n",
    "            batch_first=True)\n",
    "\n",
    "\n",
    "    def get_embeddings(self, word_seqs, target_colors=None):\n",
    "        # word_seqs -> (m, k)\n",
    "        word_seqs_embedding = self.embedding(word_seqs) # -> (m, k, embed_dim)\n",
    "        # target_colors -> (m, c)\n",
    "        target_colors = torch.unsqueeze(target_colors, 1) # -> (m, 1, c)\n",
    "        target_colors_across_word_seqs = torch.repeat_interleave(target_colors, word_seqs.shape[1], dim=1) # -> (m, k, c)\n",
    "\n",
    "        return torch.cat((word_seqs_embedding, target_colors_across_word_seqs), dim=2) # -> (m, k, embed_dim + c)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_color_describer import EncoderDecoder\n",
    "\n",
    "class ColorizedEncoderDecoder(EncoderDecoder):\n",
    "\n",
    "    def forward(self,\n",
    "            color_seqs,\n",
    "            word_seqs,\n",
    "            seq_lengths=None,\n",
    "            hidden=None,\n",
    "            targets=None):\n",
    "        if hidden is None:\n",
    "            hidden = self.encoder(color_seqs)\n",
    "\n",
    "        # color_seqs -> (m, 3, color_dim)\n",
    "\n",
    "        target_color_seq = color_seqs[:, 2, :] # -> (m, 1, color_dim)\n",
    "        target_color_seq = torch.squeeze(target_color_seq, dim=1) # -> (m, color_dim)\n",
    "\n",
    "        output, hidden = self.decoder(\n",
    "            word_seqs, seq_lengths=seq_lengths, hidden=hidden, target_colors=target_color_seq)\n",
    "\n",
    "        if self.training:\n",
    "            return output\n",
    "        else:\n",
    "            return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_color_describer import Encoder\n",
    "\n",
    "class ColorizedInputDescriber(ContextualColorDescriber):\n",
    "\n",
    "    def build_graph(self):\n",
    "\n",
    "        encoder = Encoder(\n",
    "            color_dim=self.color_dim,\n",
    "            hidden_dim=self.hidden_dim)\n",
    "\n",
    "        color_context_decoder = ColorContextDecoder(\n",
    "            color_dim=self.color_dim,\n",
    "            vocab_size=self.vocab_size,\n",
    "            embed_dim=self.embed_dim,\n",
    "            embedding=self.embedding,\n",
    "            hidden_dim=self.hidden_dim,\n",
    "            freeze_embedding=self.freeze_embedding)\n",
    "\n",
    "        return ColorizedEncoderDecoder(encoder, color_context_decoder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_full_system(describer_class):\n",
    "    toy_color_seqs, toy_word_seqs, toy_vocab = create_example_dataset(\n",
    "        group_size=50, vec_dim=2)\n",
    "\n",
    "    toy_color_seqs_train, toy_color_seqs_test, toy_word_seqs_train, toy_word_seqs_test = \\\n",
    "        train_test_split(toy_color_seqs, toy_word_seqs)\n",
    "\n",
    "    toy_mod = describer_class(toy_vocab)\n",
    "\n",
    "    _ = toy_mod.fit(toy_color_seqs_train, toy_word_seqs_train)\n",
    "\n",
    "    acc = toy_mod.listener_accuracy(toy_color_seqs_test, toy_word_seqs_test)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished epoch 1000 of 1000; error is 0.11461793631315231"
     ]
    },
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_full_system(ColorizedInputDescriber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 71. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 43.2279314994812"
     ]
    }
   ],
   "source": [
    "# trying this model to get a ballpark for its performance\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    decoder_with_target_dev_mod = ColorizedInputDescriber(\n",
    "        dev_vocab,\n",
    "        embed_dim=128,\n",
    "        hidden_dim=128,\n",
    "        optimizer_class=torch.optim.Adam,\n",
    "        eta=0.001,\n",
    "        early_stopping=True)\n",
    "\n",
    "    _ = decoder_with_target_dev_mod.fit(dev_cols_train, dev_seqs_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listener_accuracy:\n",
      " 0.8016124388137057\n",
      "bleu:\n",
      " 0.6622045640998858\n"
     ]
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    print(\"listener_accuracy:\\n\", decoder_with_target_dev_mod.listener_accuracy(dev_cols_test, dev_seqs_test))\n",
    "    print(\"bleu:\\n\", decoder_with_target_dev_mod.corpus_bleu(dev_cols_test, dev_seqs_test)[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This model on default parameters,\n",
    "-> listener_accuracy: 0.780, bleu: 0.664\n",
    "-> embedding + hidden dim = 100, 0.7929, 0.6626 (for embedding + hidden dim 200 or so, accuracy reduces)\n",
    "-> embed_dim 200 + hidden_dim 100, gives a reduced perf of 0.789 accuracy.\n",
    "-> **_embed_dim + hidden_dim 128, listener_accuracy: 0.7953, bleu: 0.6615_**\n",
    "-> **_similar to above, embed_dim + hidden_dim 128, optim adam+eta 0.001, listener_accuracy:0.802, bleu: 0.662_**\n",
    "-> embed_dim + hidden_dim 128 optim Adam + eta 0.004, listener_accuracy: 0.783, bleu: 0.657\n",
    "-> Adadelta + eta 0.2 does not produce good results."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original system"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Apart from the experiments above, lets try some really promising techniques, like BERT representations in the Embedding Matrix, regularazation, etc. Since BERT embeddings are extremely costly to generate, we choose to generate it for the full train vocab at once. An enumeration of few things to try while integration:\n",
    "\n",
    "1. Generate training data/vocab with some trimming on words (to represent them as \\<UNK\\>\n",
    "2. Bert tokenization and representation for the entire train vocab to use them as the embedding matrix for the decoder later.\n",
    "3. Use fourier transformed color space as color feature vectors\n",
    "4. Do some experiments with the actual encoder decoder structure.\n",
    "5. Optimize for hyper-parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Generating full data and truncating vocab set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples:\n",
      " 46994\n"
     ]
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    full_corpus = ColorsCorpusReader(\n",
    "        COLORS_SRC_FILENAME,\n",
    "        normalize_colors=True)\n",
    "\n",
    "    full_examples = list(full_corpus.read())\n",
    "\n",
    "    print(\"Total examples:\\n\", len(full_examples))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    full_rawcols, full_texts = zip(*[[ex.colors, ex.contents] for ex in full_examples])\n",
    "    full_rawcols_train, full_rawcols_test, full_texts_train, full_texts_test = \\\n",
    "    train_test_split(full_rawcols, full_texts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vocab size:\n",
      " 2997\n",
      "Total vocab words removed:\n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    full_train_vocab, filled_full_train_word_seqs, full_train_removed_words = create_vocab_from_content_dataset(train_texts=full_texts_train, lowest_allowed_freq=1, tokenizer=tweet_tokenize)\n",
    "\n",
    "    print(\"Total vocab size:\\n\", len(full_train_vocab))\n",
    "    print(\"Total vocab words removed:\\n\", len(full_train_removed_words))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    def full_tokenize_example(s):\n",
    "        return tokenize_example_on_vocab(s, train_vocab=full_train_vocab, tokenizer=tweet_tokenize)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    full_seqs_train = [full_tokenize_example(s) for s in full_texts_train]\n",
    "    full_seqs_test = [full_tokenize_example(s) for s in full_texts_test]\n",
    "    full_cols_train = [represent_color_context(colors) for colors in full_rawcols_train]\n",
    "    full_cols_test = [represent_color_context(colors) for colors in full_rawcols_test]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    full_mod = ContextualColorDescriber(\n",
    "        full_train_vocab,\n",
    "        early_stopping=True)\n",
    "\n",
    "    %time _ = full_mod.fit(full_cols_train, full_seqs_train)\n",
    "\n",
    "    print(\"listener_accuracy:\\n\", full_mod.listener_accuracy(full_cols_test, full_seqs_test))\n",
    "    print(\"bleu:\\n\", full_mod.corpus_bleu(full_cols_test, full_seqs_test)[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**_Baseline for full train vocab: listener_accuracy: 0.832, bleu: 0.448_**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [],
   "source": [
    "# trying to increase the relevant vocab size\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    from matplotlib import colors as mcolors\n",
    "\n",
    "    colors = dict(mcolors.BASE_COLORS, **mcolors.CSS4_COLORS)\n",
    "    color_vocab = colors.keys()\n",
    "    color_vocab = [color_word.lower() for color_word in color_vocab if len(color_word) > 2]\n",
    "\n",
    "    def is_subseq(x, y):\n",
    "        it = iter(y)\n",
    "        # return all(any(c == ch for c in it) for ch in x)\n",
    "        is_subsequence = False\n",
    "        max_seq_count = 4\n",
    "        curr_seq_count = 0\n",
    "\n",
    "        for ch in x:\n",
    "            if any(c == ch for c in it):\n",
    "                curr_seq_count+=1\n",
    "                if curr_seq_count == max_seq_count:\n",
    "                    is_subsequence = True\n",
    "                    break\n",
    "        return is_subsequence\n",
    "\n",
    "    def get_rare_vocab_from_banned_words(rejected_words):\n",
    "        wild_card_vocab = []\n",
    "        ctr = 0\n",
    "\n",
    "        for removed_word in rejected_words:\n",
    "            for color_word in color_vocab:\n",
    "                if is_subseq(color_word, removed_word):\n",
    "                    ctr += 1\n",
    "                    wild_card_vocab.append(removed_word)\n",
    "                    break\n",
    "\n",
    "        wild_card_vocab = set(wild_card_vocab)\n",
    "        still_removed_words = set(rejected_words) - wild_card_vocab\n",
    "        # print(wild_card_vocab)\n",
    "        # print(\"Total infrequent words with some color information:\\n\", ctr)\n",
    "        return sorted(wild_card_vocab), sorted(still_removed_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [],
   "source": [
    "# if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "#     rare_vocab, truly_banned_vocab = get_rare_vocab_from_banned_words(full_train_removed_words)\n",
    "    # print(rare_vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**_This is an attempt to extract even more relevant color words from the infrequent words_**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    from collections import Counter\n",
    "\n",
    "    def create_tweaked_vocab_from_content_dataset(train_texts, lowest_allowed_freq, tokenizer):\n",
    "        train_word_seqs = [tokenizer(text) for text in train_texts]\n",
    "        train_words_list = [word for word_seq in train_word_seqs for word in word_seq]\n",
    "\n",
    "        ctr_train_words_list = Counter(train_words_list)\n",
    "        banned_words = [k for (k, v) in ctr_train_words_list.most_common() if v < lowest_allowed_freq]\n",
    "        banned_words = set(banned_words)\n",
    "\n",
    "        train_words_vocab = sorted(set(train_words_list) - banned_words)\n",
    "\n",
    "        rare_train_vocab, truly_banned_train_vocab = get_rare_vocab_from_banned_words(banned_words)\n",
    "\n",
    "        tweaked_train_words_vocab = sorted(set(train_words_vocab + rare_train_vocab))\n",
    "        tweaked_train_words_vocab += [UNK_SYMBOL]\n",
    "\n",
    "        filled_tweaked_train_word_seqs = [[word if word not in truly_banned_train_vocab else UNK_SYMBOL for word in word_seq] for word_seq in train_word_seqs]\n",
    "\n",
    "        return tweaked_train_words_vocab, filled_tweaked_train_word_seqs, truly_banned_train_vocab\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vocab size:\n",
      " 1839\n",
      "Total vocab words removed:\n",
      " 1158\n",
      "Words removed from vocab:\n",
      " ['#49', '. . .', '. ..', '1.50', '13', '14', '15', '2012', '30s', '3rd', '4', '49/50', '5', '6', '7', ':-/', ':\\\\', ';-)', '=(', '=/', '=]', '___poppy', 'aaagh', 'abright', 'absence', 'accurate', 'ack', 'acronynyms', 'add', 'address', 'ahah', 'ahahha', 'ahhh', 'aka', 'album', 'alittle', 'alive', 'almsot', 'alomst', 'aloud', 'although', 'amazing', 'amost', 'anyone', 'anyways', 'apparel', 'appear', 'appears', 'appicane', 'apply', 'apposed', 'appreciate', 'arange', 'arent', 'aretha', 'arg', 'argh', 'arghhhhhhhhhhhhhhhh', 'argue', 'armyish', 'art', 'artist', 'athe', 'aua', 'auqa', 'autumn', 'avacado', 'available', 'avocados', 'awareness', 'away', 'aweome', 'awful', 'awhile', 'awkward', 'b.ue', 'babby', 'babyfood', 'baige', 'barf', 'barn', 'barneys', 'barnier', 'barnys', 'basketball', 'beach', 'bear', 'bee', 'berries', 'bfight', 'biege-tan', 'biggest', 'biking', 'bin', 'bingo', 'bird', 'birghtest', 'birhg', 'birte', 'bismol', 'bkue', 'ble', 'blie', \"blu'ish\", 'bluosh', 'blurdt', 'blusih', 'bluw', 'bly', 'boat', 'bodied', 'boogies', 'book', \"boy's\", 'braindead', 'brand', 'brat', 'bravo', 'bread', 'breast', 'brickish', 'bricks', 'bridesmaid', 'brigether', 'brigh', 'brighet', 'brighhtest', 'brighly', 'brighness', 'brighteset', 'brightess', 'brightet', 'brightiest', 'brightp', 'brightre', 'brighttest', 'brighttttt', 'brigt', 'brigth', 'brihgt', 'brishtest', 'brite-ist', 'brither', 'briwn', 'bro', 'broen', 'bron', 'brothers', 'bruight', 'bu', 'buddy', 'bueb', 'bull', 'bullish', 'bulls', 'bummer', 'burgandy', 'burgundy', 'bush', 'bustin', 'butnot', 'bye', 'c', 'cadillac', 'cadillacs', 'calibrated', 'calibration', 'calm', 'canary', 'cancer', 'cape', 'cardbord', 'carmel', 'carrot', 'cat', 'caught', 'cent', 'certain', 'chalk', 'chat', 'cheating', 'checkrobe', 'cheeks', 'cheeriest', 'cheerios', 'cheers', 'cheese', 'chicago', 'chick', 'chiminea', 'clash', 'class', 'clay-ish', 'clcik', 'cleveland', 'cloests', 'clored', 'closeist', 'closes', 'closetst', 'clostest', 'clothes', 'clothing', 'cloths', 'cloudless', 'coclor', 'cocoa', 'coffe', 'cold', 'collor', 'cologe', 'colorwise', 'colr', 'combined', 'comments', 'complete', 'completely', 'computers', 'concord', 'contacting', 'contain', 'cookie', 'coolest', 'coor', 'couldnt', 'count', 'counted', 'crater', 'crayola', 'crayons', 'crazy', 'cream', 'creamier', 'creamish', 'creme', 'cremish', 'crisp', 'cross', 'cruel', 'cuz', \"d'oh\", 'da', 'dadull', 'dafflodils', 'daffodil', 'damned', 'dandelion', 'dangerous', 'dangit', 'dar', 'darest', 'darish', 'darts', 'dary', 'dash', 'days', 'dcale', 'deal', 'deere', 'def', 'dell', 'desaturated', 'descibe', 'descibing', 'described', 'descript', 'desert', 'di', 'diareah', \"didn't\", 'died', 'diff', 'diffeeent', 'differenmt', 'differnet', 'difficult', 'dijon', 'dillest', 'diluted', 'dimmed', 'dimmest', 'dingiest', 'dinosaure', 'dinosaurer', 'dinosour', 'directions', 'dirtiest', 'discern', 'displays', 'distinctively', 'diuller', 'dlllest', 'dog', 'doin', 'dokie', 'dole', 'dolphins', 'doodoo', 'dooo', 'dr', 'dragger', 'drak', 'dress', 'drker', 'drkest', 'drops', 'drrkest', 'drunk', 'dsrk', 'duck', 'dude', 'duke', 'dulest', 'dulled', 'dullezt', 'dullist', 'dumb', 'during', 'dusk', 'duskier', 'eal', 'earthier', 'eeyore', 'eggs', 'ehh', 'electric', 'eletric', 'em', 'enjoy', 'enjoyed', 'enjoying', 'entrails', 'envy', 'eque', 'er', 'erange', 'eraser', 'erasers', 'etc', 'everything', 'everywhere', 'exaclty', 'exact', 'example', 'exists', 'exit', 'expensive', 'expert', 'expired', 'explain', 'explorer', 'explosion', 'ezpz', 'f', 'fading', 'failing', 'faint', 'faintly', 'faiult', 'familiar', 'famous', 'fan', 'fark', 'farkish', 'farthest', 'fascia', 'fawn', 'feedback', 'feelin', 'feels', 'female', 'fern', 'fhe', 'finished', 'fish', 'five', 'flashiest', 'flattest', 'fleash', 'fleshy', 'foamish', 'foamy', 'focusing', 'form', 'found', 'franklin', 'freakin', 'freaking', 'freeze', 'freezing', 'fresh', 'frogish', 'fuller', 'further', 'furthest', 'fuzzy', 'g', 'games', 'gark', 'gases', 'gatorade', 'gayish', 'geez', 'general', 'generic', 'georgia', 'gery', 'geryish', 'gettin', 'gey', 'gg', 'ghrren', 'girlish', 'given', 'gjgjgjg', 'glitchy', 'glow', 'glowing', 'goes', 'goinf', 'goo', 'goodness', 'gra', 'graphic', 'grasslike', 'grean', 'greish', 'greist', 'grenn', 'grief', 'group', 'grows', 'grrenish', 'grrnish', 'grrrrr', 'grrya', 'guac', 'gull', 'gum', 'gunmetal', 'guys', 'hahahaha', 'hahahahahha', 'hair', 'half', 'halfway', 'halloweenish', 'halowwen', 'handful', 'hang', 'happen', 'happy', 'hardest', \"hasn't\", \"haven't\", 'hdtv', 'heading', 'heads', 'healthy', 'heard', 'heart', 'heat', 'heathered', 'heck', 'help', 'helpful', 'herb', 'heyya', 'highest', 'hink', 'hinted', 'hinter', 'his', 'hiya', 'hlad', 'hmhm', 'hmmmm', 'home', 'homie', 'hooo', 'hooray', 'hopeless', 'hotdog', 'housee', 'howdy', 'however', 'hrm', 'hubby', 'human', 'hunting', 'hurry', 'hurts', 'icey', 'icing', 'icon', 'icy', 'iddle', 'idiot', 'ieange', 'ighter', 'iis', 'ilght', 'ill', 'impossible', 'improving', 'indeed', 'ine', 'infront', 'inot', 'instead', 'instructions', 'int', 'intensity', 'interesting', 'internet', 'intesne', 'inthe', 'ios', 'irabge', 'irange', 'irritating', 'isa', 'ishard', 'ismost', 'iss', 'jealoushy', 'jeans', 'jewel', 'jewelry', 'jimmy', 'jiob', 'jk', 'jo', 'job-not', 'john', 'joining', 'jr', 'jummy', 'kakhi', 'kay', 'keeps', 'kess', 'ketchup', 'kid', 'kight', 'killin', 'knew', 'kniucle', 'known', 'knuckle', 'kool', 'kow', 'labels', 'lacking', 'lackluster', 'lake', 'lame', 'lant', 'lapis', 'laptop', 'later', 'laundry', 'lazuli', 'lazy', 'lean', 'learning', 'lease', 'legit', 'lest', 'let', 'letter', 'letting', 'lght', 'lgiht', 'life', 'ligt', 'likea', 'lilc', 'liliac', 'limit', 'limr', 'lining', 'link', 'litest', 'litle', 'living', 'location', 'locations', 'logo', 'loks', 'lols', 'lookinh', 'lool', 'loook', 'loops', 'lord', 'lost', 'loud', 'loudest', 'loved', 'lovely', 'lowest', 'lttle', 'lucky', 'lueish', 'lunch', 'mac', 'mad', 'madder', 'mahogany', 'male', \"man's\", 'marine', 'marker', 'mary', 'mash', 'matches', 'matching', 'maube', 'mauvy', 'mave', 'meaning', 'meet', 'melon', 'mentioned', 'mic', 'middle-hue', 'middle-type', 'middlish', 'midway', 'milk', 'mind', 'minimum', 'missing', 'mittens', 'mixing', 'mized', 'mm', 'mmm', 'moon', 'mor', 'more-so', 'morning', 'mos', 'mossier', 'mot', 'mow', 'mtg', 'mucus', 'muddier', 'muppet', 'mushy', 'mustards', 'mustart', 'mute', 'muve', 'mybad', 'mylanta', 'nail', 'narwhal', 'nat', 'naw', 'nawh', 'nbd', 'nd', 'nearest', 'negative', \"neon'ish\", 'neon-esque', 'neon-ish', 'neone', 'neonest', 'neony', 'netiher', 'nick', 'nighttime', 'niiiiiiice', 'ninentendo', 'nk', 'nmeded', 'nnnnoooo', 'non-bright', 'non-muted', 'non-neon', 'non-reddish', 'non-target', 'nono', 'nooooo', 'not-as-bright', 'not-bright', 'nother', 'nothing', 'noy', 'npt', 'nrightest', 'nude', 'nut', 'nweird', 'oastel', 'oblong', 'obnoxious', 'oceanlike', 'oddball', 'oen', 'ohh', 'ohhh', 'oi', 'oilve', 'oink', 'okie', 'okkkk', 'olve', 'omre', 'one--the', 'one-not', 'one.the', 'onebut', 'onr', 'oo', 'ooo', 'oooh', 'opinion', 'ops', 'orage', 'order', 'orders', 'ornage', 'ose', 'ot', \"ot's\", 'otange', 'ouch', 'oueple', 'ouj', 'ourple', 'ours', 'overtones', 'owe', 'oye', 'p8', 'p;', 'pack', 'pain', 'painted', 'palish', 'park', 'parker', 'parrot', 'passsed', 'pastels', 'patel', \"patrick's\", 'pay', 'payed', 'pea-ish', 'pear', 'peel', 'pencil', 'per', 'perception', 'perhaps', 'periwinle', 'personally', 'peuple', 'pf', 'phot', 'picture', 'pie', 'pigment', 'piles', 'pimk', 'pinish', 'piss', 'pistacchio', 'pit', 'pixels', 'plant', \"plant's\", 'plants', \"plat's\", 'player', 'pnik', 'poilish', 'policemans', 'ponk', 'poopish', 'pop', 'poppingest', 'popular', 'porn', 'posh', 'position', 'possibly', 'pot', 'power', 'practically', 'precious', 'prettiest', 'priple', 'probly', 'process', 'product', 'prp', 'prussian', 'ps', 'pu', 'puce', 'pukey-kind', 'pumkin', 'pumpkins', 'pumpkn', 'punk', 'pup', 'pupr', 'purble', 'purlish', 'puse', 'q', 'qq', 'quality', 'queed', 'quick', 'quit', 'raddish', 'radiant', 'rained', 'randomly', 'ranger', 'raspberry', 'rats', 'realy', 'reason', 'recently', 'recover', 'red-ness', 'red-tone', 'redd', 'redderish', 'reddist', 'reddsih', 'reddy', 'reder', 'reed', 'reen', 'refer', 'reg', 'rel', 'related', 'remotely', 'repeat', 'res', 'review', 'rey', 'rgeen', 'richc', 'rid', 'ridiculous', 'rly', 'roayl', \"robbin's\", 'rockin', 'rocking', 'roseish', 'roses', 'rosier', 'rotting', 'roudn', 'rough', 'rougish', 'rounds', 'row', 'roy', 'rple', 'rsky', 'rsut', 'rubber', 'rude', 'rule', 'run', 'running', 'sadness', 'sag', 'same-ish', 'sang', 'says', 'school', 'schoolbus', 'scree', 'sea-foam', 'seafoamy', 'seahawk', 'seal', 'seattkle', 'seattle', 'sec', 'seeemed', 'seemingly', 'setting', 'sexist', 'sgood', 'shad', 'shae', 'shafe', 'shake', 'shape', 'shark', \"she's\", 'sherbert', 'shickingly', 'shinny', 'ship', 'shirt', 'shocking', 'shoot', \"should've\", 'shouldve', 'shrugs', 'sidewalk', 'sidnna', 'silly', 'simalar', 'siml', 'simlar', 'since', 'singer', 'single', 'sk', 'skt', 'sky-like', 'skyer', 'skyish', 'skys', 'slamon-like', 'slimy', 'slivre', 'slow', 'slughtly', 'smallest', 'smartest', 'smells', 'snot', 'soda', 'soe', 'solor', 'solors', 'somewhere', 'soo', 'soooo', 'soothing', 'sorrry', 'sory', 'soudns', 'sound', 'southwest', 'sparrow', 'speed', 'spelling', 'spicy', 'spilled', 'spit', 'squars', 'squatty', 'squint', 'squirt', 'srry', 'st', 'stalks', 'starting', 'stated', 'states', 'stay', 'step', 'stiks', 'stinking', 'store', 'stress', 'stuff', 'subtly', 'such', 'sucked', 'superman', 'swear', 'swimming', 't5he', 'tab', 'talk', 'tan-like', 'tanb', 'tanned', 'tanny', 'tans', 'tart', 'taste', 'taupe--not', 'tcu', 'tea', 'teammwork', 'teamwork', 'tee', 'tela', 'tellow', 'tend', 'terracotta-ish', 'text', 'thanks-i', 'thanksgiving', 'thee', 'thin', 'thing--pick', 'third', 'thop', 'thoroughly', 'thoughts', 'through', 'throwing', 'throws', 'tht', 'ticket', 'tiger', 'timer', 'tinges', 'tinit', 'tink', 'tinnt', 'tinting', 'tiny', 'tks', 'tne', 'toilet', 'told', 'torquois', 'torquoise', 'torquoisw', 'torture', 'total', 'tougher', 'toughie', 'toupe', 'toward', 'tractor', 'traffic', 'tranquil', 'tranquility', 'trees', 'trf', 'trouble', 'trtner', 'trueist', 'trump', 'trunk', 'trust', 'tthe', 'tuff', 'turkernation', 'turkmaster', 'turkopitcon', 'turned', 'turns', 'tutus', 'tweetie', 'twice', 'ty', 'typed', 'u2', 'ughh', 'ughhh', 'uhhh', 'uhhhhh', 'uhhm', 'uhmm', 'ummmm', 'ummmnot', 'uniform', 'united', 'unless', 'unsweeten', 'usixels', 'usual', 'value', 'values', 'variation', 'variations', 'varients', 'vary', 'vegie', 'verge', 'versus', 'vibratnt', 'viloet', 'vivd', 'vivied', 'vlose', 'vlue', 'vocabulary', 'volunteer', 'volunteers', 'vomited', 'wack', 'waht', 'walpaper', 'wanna', 'wanted', 'warning', 'wasabi', 'washout', 'wat', 'watered', 'watery', 'ways', \"we'll\", 'wear', 'weathered', 'weirder', 'went', 'west', 'weve', 'while', 'wiat', 'wiith', 'winkle', 'wins', 'wisley', 'witha', 'wityh', \"women's\", 'wondering', 'wonky', 'wont', 'woot', 'worj', 'worn', 'worrie', 'worried', 'worrries', 'worst', 'worth', \"wouldn't\", 'write', 'wrote', 'xp', 'yaeeaaa', 'yah', 'yallow', 'yard', 'ye', 'yeh', 'yelower', 'yess', 'yippee', 'yllow', 'yllw', 'yo', 'youd', \"your're\", 'yrp', 'ys', 'yuck', 'ywllow']\n",
      "A sample tokenized train text:\n",
      " ['<s>', 'purple', '</s>']\n",
      "And the actual text was:\n",
      " purple\n"
     ]
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    full_tweaked_train_vocab, filled_full_tweaked_train_word_seqs, full_train_tweaked_removed_words = create_tweaked_vocab_from_content_dataset(train_texts=full_texts_train, lowest_allowed_freq=2, tokenizer=tweet_tokenize)\n",
    "\n",
    "    print(\"Total vocab size:\\n\", len(full_tweaked_train_vocab))\n",
    "    print(\"Total vocab words removed:\\n\", len(full_train_tweaked_removed_words))\n",
    "    print(\"Words removed from vocab:\\n\", full_train_tweaked_removed_words)\n",
    "    print(\"A sample tokenized train text:\\n\", filled_full_tweaked_train_word_seqs[360])\n",
    "    print(\"And the actual text was:\\n\", full_texts_train[360])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    def tweak_tokenize_example(s):\n",
    "        return tokenize_example_on_vocab(s, train_vocab=full_tweaked_train_vocab, tokenizer=tweet_tokenize)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    full_tweaked_seqs_train = [tweak_tokenize_example(s) for s in full_texts_train]\n",
    "    full_tweaked_seqs_test = [tweak_tokenize_example(s) for s in full_texts_test]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    full_cols_train = [represent_color_context(colors) for colors in full_rawcols_train]\n",
    "    full_cols_test = [represent_color_context(colors) for colors in full_rawcols_test]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    full_tweaked_mod = ContextualColorDescriber(\n",
    "        full_tweaked_train_vocab,\n",
    "        early_stopping=True)\n",
    "\n",
    "    %time _ = full_tweaked_mod.fit(full_cols_train, full_tweaked_seqs_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\My Drive\\MLDL\\stanfordXCS224U\\referenceRepo\\cs224u\\torch_color_describer.py:680: RuntimeWarning: divide by zero encountered in power\n",
      "  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listener_accuracy:\n",
      " 0.8235594518682441\n",
      "bleu:\n",
      " 0.4511033513493236\n"
     ]
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    print(\"listener_accuracy:\\n\", full_tweaked_mod.listener_accuracy(full_cols_test, full_tweaked_seqs_test))\n",
    "    print(\"bleu:\\n\", full_tweaked_mod.corpus_bleu(full_cols_test, full_tweaked_seqs_test)[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tweaking dataset **_removed about 1100 (33%) vocab words_** and yet the model **_retains the performance with an improved bleu score_**,\n",
    "**_default tweaked model,\n",
    "listener_accuracy: 0.831-0.82356\n",
    "bleu: 0.45_**\n",
    "\n",
    "This shows that **_almost 33% vocab words (rare words) were almost inconsequencial_** to the model's learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Generating train vocab BERT Embeddings that can be used with decoder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "\n",
    "    from transformers import BertModel, BertTokenizer\n",
    "    import vsm\n",
    "\n",
    "    bert_weights_name = 'bert-base-uncased'\n",
    "    bert_tokenizer = BertTokenizer.from_pretrained(bert_weights_name)\n",
    "    bert_model = BertModel.from_pretrained(bert_weights_name)\n",
    "\n",
    "    global ctr\n",
    "    ctr = 0\n",
    "\n",
    "    def hf_bert_phi(text):\n",
    "        text_bert_ids = vsm.hf_encode(text, bert_tokenizer,\n",
    "                                    add_special_tokens=True)\n",
    "\n",
    "        text_bert_reps = vsm.hf_represent(text_bert_ids, bert_model, layer=-1) # -> (1, x, 768)\n",
    "\n",
    "        global ctr\n",
    "        if ctr%100 == 0:\n",
    "            print(\"Bert encoding done for ctr \", ctr)\n",
    "        ctr+=1\n",
    "\n",
    "        return torch.mean(text_bert_reps[0], axis=0).cpu().numpy()\n",
    "\n",
    "    # to save time even on a re-run, lets create bert embeddings for all the words in the dataset. We will however inject the model with only the embeddings for the vocab, that is decided for the training set (different in different runtimes).\n",
    "\n",
    "    # lookup to create embeddings\n",
    "    def create_bert_embedding_lookup_on_text_corpora(text_corpora, tokenizer):\n",
    "        corpora_word_seqs = [tokenizer(text) for text in text_corpora]\n",
    "        corpora_words_list = [word for word_seq in corpora_word_seqs for word in word_seq]\n",
    "\n",
    "        corpora_words_set = list(sorted(set(corpora_words_list)))\n",
    "        corpora_word_bert_embedding = {word:hf_bert_phi(word) for word in corpora_words_set}\n",
    "\n",
    "        return corpora_word_bert_embedding\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    %time full_corpora_word_bert_embedding = create_bert_embedding_lookup_on_text_corpora(full_texts, tweet_tokenize)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "\n",
    "    def create_bert_embedding(vocab, bert_lookup):\n",
    "        bert_embedding, bert_vocab = utils.create_pretrained_embedding(bert_lookup, vocab)\n",
    "\n",
    "        return bert_embedding, bert_vocab"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    full_train_bert_embedding, full_train_bert_vocab = create_bert_embedding(full_train_vocab, full_corpora_word_bert_embedding)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# testing the performance of BERT embeddings in the decoder\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    full_bert_embedding_mod = ContextualColorDescriber(\n",
    "        full_train_bert_vocab,\n",
    "        embedding=full_train_bert_embedding,\n",
    "        hidden_dim=512,\n",
    "        early_stopping=True)\n",
    "\n",
    "    %time _ = full_bert_embedding_mod.fit(full_cols_train, full_seqs_train)\n",
    "\n",
    "    print(\"listener_accuracy:\\n\", full_bert_embedding_mod.listener_accuracy(full_cols_test, full_seqs_test))\n",
    "    print(\"bleu:\\n\", full_bert_embedding_mod.corpus_bleu(full_cols_test, full_seqs_test)[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Default model performance,\n",
    "listener_accuracy: 0.8288, bleu: 0.472:\n",
    "\\+ hidden_dim 256, listener_accuracy: 0.8453, bleu: 0.438\n",
    "**_+ hidden_dim 512, 0.850, 0.447 (accuracy reduces for a greater value of 728)_**\n",
    "in all of them eta stays 0.001 (default)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. BERT on color input Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# trying this model to get a ballpark for its performance\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    full_bert_embedding_color_input_mod = ColorizedInputDescriber(\n",
    "        full_train_bert_vocab,\n",
    "        embedding=full_train_bert_embedding,\n",
    "        hidden_dim=256,\n",
    "        early_stopping=True)\n",
    "\n",
    "    _ = full_bert_embedding_color_input_mod.fit(full_cols_train, full_seqs_train)\n",
    "\n",
    "    print(\"listener_accuracy:\\n\", full_bert_embedding_color_input_mod.listener_accuracy(full_cols_test, full_seqs_test))\n",
    "    print(\"bleu:\\n\", full_bert_embedding_color_input_mod.corpus_bleu(full_cols_test, full_seqs_test)[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Scores:\n",
    "default +hidden_dim = 512, listener_accuracy: 0.845, bleu: 0.451\n",
    "\\+ hidden_dim = 256, 0.849, 0.453 (score reduces for <256 hidden_dim)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Custom Encoder-Decoder Model (Experimental, encoder_hidden_dim always equals decoder_hidden_dim)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "\n",
    "    class ExpColorContextDecoder(ColorContextDecoder):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "\n",
    "            self.rnn = nn.LSTM(\n",
    "                input_size=self.embed_dim + self.color_dim,\n",
    "                hidden_size=self.hidden_dim,\n",
    "                num_layers=2,\n",
    "                batch_first=True,\n",
    "                dropout=0.8,\n",
    "                bidirectional=False\n",
    "            )\n",
    "            self.output_layer = nn.Linear((int(self.rnn.bidirectional) + 1) * self.hidden_dim, self.vocab_size)\n",
    "\n",
    "    class ExpEncoder(Encoder):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "\n",
    "            self.rnn = nn.LSTM(\n",
    "                input_size=self.color_dim,\n",
    "                hidden_size=self.hidden_dim,\n",
    "                num_layers=2,\n",
    "                batch_first=True,\n",
    "                dropout=0.8,\n",
    "                bidirectional=False\n",
    "            )\n",
    "\n",
    "    class ExpColorizedEncoderDecoder(ColorizedEncoderDecoder):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "\n",
    "        def forward(self,\n",
    "            color_seqs,\n",
    "            word_seqs,\n",
    "            seq_lengths=None,\n",
    "            hidden=None,\n",
    "            targets=None):\n",
    "\n",
    "            if hidden is None:\n",
    "                hidden = self.encoder(color_seqs)\n",
    "\n",
    "            # color_seqs -> (m, 3, color_dim)\n",
    "            target_color_seq = color_seqs[:, 2, :] # -> (m, 1, color_dim)\n",
    "            target_color_seq = torch.squeeze(target_color_seq, dim=1) # -> (m, color_dim)\n",
    "\n",
    "            output, hidden = self.decoder(\n",
    "                word_seqs, seq_lengths=seq_lengths, hidden=hidden, target_colors=target_color_seq)\n",
    "\n",
    "            if self.training:\n",
    "                return output\n",
    "            else:\n",
    "                return output, hidden\n",
    "\n",
    "\n",
    "    class ExpColorizedInputDescriber(ColorizedInputDescriber):\n",
    "        def __init__(self, encoder_hidden_dim=50, decoder_hidden_dim=50, *args, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "            self.encoder_hidden_dim = encoder_hidden_dim\n",
    "            self.decoder_hidden_dim = decoder_hidden_dim\n",
    "\n",
    "            # to easily find if self.hidden_dim is being used elsewhere\n",
    "            self.hidden_dim = 0\n",
    "            self.params += ['encoder_hidden_dim', 'decoder_hidden_dim']\n",
    "\n",
    "        def build_graph(self):\n",
    "            encoder = ExpEncoder(\n",
    "                color_dim=self.color_dim,\n",
    "                hidden_dim=self.encoder_hidden_dim\n",
    "            )\n",
    "\n",
    "            decoder = ExpColorContextDecoder(\n",
    "                color_dim=self.color_dim,\n",
    "                vocab_size=self.vocab_size,\n",
    "                embed_dim=self.embed_dim,\n",
    "                embedding=self.embedding,\n",
    "                hidden_dim=self.decoder_hidden_dim,\n",
    "                freeze_embedding=self.freeze_embedding\n",
    "            )\n",
    "\n",
    "            return ExpColorizedEncoderDecoder(encoder, decoder)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "\n",
    "    def test_exp_full_system(describer_class):\n",
    "        toy_color_seqs, toy_word_seqs, toy_vocab = create_example_dataset(\n",
    "            group_size=50, vec_dim=2)\n",
    "\n",
    "        toy_color_seqs_train, toy_color_seqs_test, toy_word_seqs_train, toy_word_seqs_test = \\\n",
    "            train_test_split(toy_color_seqs, toy_word_seqs)\n",
    "\n",
    "        toy_mod = describer_class(vocab=toy_vocab, encoder_hidden_dim=32, decoder_hidden_dim=256)\n",
    "\n",
    "        _ = toy_mod.fit(toy_color_seqs_train, toy_word_seqs_train)\n",
    "\n",
    "        acc = toy_mod.listener_accuracy(toy_color_seqs_test, toy_word_seqs_test)\n",
    "\n",
    "        return acc\n",
    "\n",
    "    # print(\"Test result:\\n\", test_exp_full_system(ExpColorizedInputDescriber))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# trying this model to get a ballpark for its performance\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    full_exp_bert_embedding_color_input_mod = ExpColorizedInputDescriber(\n",
    "        vocab=full_train_bert_vocab,\n",
    "        embedding=full_train_bert_embedding,\n",
    "        encoder_hidden_dim=256,\n",
    "        decoder_hidden_dim=256,\n",
    "        early_stopping=True)\n",
    "\n",
    "    _ = full_exp_bert_embedding_color_input_mod.fit(full_cols_train, full_seqs_train)\n",
    "\n",
    "    print(\"listener_accuracy:\\n\", full_exp_bert_embedding_color_input_mod.listener_accuracy(full_cols_test, full_seqs_test))\n",
    "    print(\"bleu:\\n\", full_exp_bert_embedding_color_input_mod.corpus_bleu(full_cols_test, full_seqs_test)[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Scores:\n",
    "Bert Embeddings + hidden_dim (256, 256) + 1 layer + unidirection, listener_accuracy: 0.852-0.8498, bleu:0.443-0.451\n",
    "\n",
    "same as above + 2 layer + dropout 0.5, 0.851, 0.451\n",
    "same as above + 2 layer + dropout 0.2, 0.8467, 0.4534\n",
    "same as above + 2 layer + dropout 0.8, 0.854, 0.447\n",
    "\n",
    "Bidirecitonal Variant **_Does not always converge_**. So we are not investigating it further. Also, this model **_still has the limitation of equal hidden_dim for both encoder and decoder. We address that later._**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. Pipeline decision\n",
    "\n",
    "We see that this `ExpColorizedInputDescriber` has all the properties of `ColorizedInputDescriber` and the general context-color based model we made earlier. On top of that this has the functionality to add more layers and regularization. **_So, we are proceeding with this model_**.\n",
    "\n",
    "We would also like to test the following in our pipeline:\n",
    "1. Roberta/Bert tokenization and per-token embedding based model (not performing quite well)\n",
    "5. Roberta/BERT embeddings on tweet tokens (nice results)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6. RoBERTa tokenizer vocab and embedding calculation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    # find the full vocab on data\n",
    "    from transformers import RobertaModel, RobertaTokenizer\n",
    "    import vsm\n",
    "\n",
    "    roberta_weights_name = 'roberta-large'\n",
    "    roberta_tokenizer = RobertaTokenizer.from_pretrained(roberta_weights_name)\n",
    "    roberta_model = RobertaModel.from_pretrained(roberta_weights_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "outputs": [],
   "source": [
    " if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "     def roberta_tokenize(s):\n",
    "         s = s.lower()\n",
    "         return roberta_tokenizer.tokenize(s)\n",
    "\n",
    "     full_roberta_train_vocab, filled_full_roberta_train_word_seqs, full_roberta_train_removed_words = create_vocab_from_content_dataset(train_texts=full_texts_train, lowest_allowed_freq=1, tokenizer=roberta_tokenize)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "\n",
    "    ctr = 0\n",
    "    def tf_phi(text, tf_tokenizer, tf_model):\n",
    "        text_tf_ids = vsm.hf_encode(text, tf_tokenizer,\n",
    "                                    add_special_tokens=True)\n",
    "\n",
    "        text_tf_reps = vsm.hf_represent(text_tf_ids, tf_model, layer=-1) # -> (1, x, 1024)\n",
    "\n",
    "        global ctr\n",
    "        if ctr%100 == 0:\n",
    "            print(\"Transformer encoding done for ctr \", ctr)\n",
    "        ctr+=1\n",
    "\n",
    "        return torch.mean(text_tf_reps[0], axis=0).cpu().numpy()\n",
    "\n",
    "    # lookup to create embeddings\n",
    "    def create_tf_embedding_lookup_on_text_vocab(vocab, tf_tokenizer, tf_model):\n",
    "        corpora_word_tf_embedding = {word:tf_phi(word, tf_tokenizer, tf_model) for word in vocab}\n",
    "\n",
    "        return corpora_word_tf_embedding\n",
    "\n",
    "    def create_tf_embedding(vocab, tf_repr_lookup):\n",
    "        tf_embedding, tf_vocab = utils.create_pretrained_embedding(tf_repr_lookup, vocab)\n",
    "        return tf_embedding, tf_vocab"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    %time full_corpora_word_roberta_embedding = create_tf_embedding_lookup_on_text_vocab(full_roberta_train_vocab, roberta_tokenizer, roberta_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    full_train_roberta_embedding, full_train_roberta_vocab = create_tf_embedding(full_roberta_train_vocab, full_corpora_word_roberta_embedding)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# trying this model to get a ballpark for its performance\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    full_exp_roberta_embedding_color_input_mod = ExpColorizedInputDescriber(\n",
    "        vocab=full_train_roberta_vocab,\n",
    "        embedding=full_train_roberta_embedding,\n",
    "        encoder_hidden_dim=256,\n",
    "        decoder_hidden_dim=256,\n",
    "        early_stopping=True)\n",
    "\n",
    "    _ = full_exp_roberta_embedding_color_input_mod.fit(full_cols_train, full_seqs_train)\n",
    "\n",
    "    print(\"listener_accuracy:\\n\", full_exp_roberta_embedding_color_input_mod.listener_accuracy(full_cols_test, full_seqs_test))\n",
    "    print(\"bleu:\\n\", full_exp_roberta_embedding_color_input_mod.corpus_bleu(full_cols_test, full_seqs_test)[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**_Clearly, transformer embeddings on context split tokens and sub-tokens dont work well. This is mainly because the transformer splits words into sub-words based on context and a separate context independent subword token representation on it would not make much sense. Wont proceed with the same on BERT or other transformers._**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7. RoBERTa embedding on sentiment-token words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "outputs": [],
   "source": [
    " if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    full_roberta_train_vocab, filled_full_roberta_train_word_seqs, full_roberta_train_removed_words = create_vocab_from_content_dataset(train_texts=full_texts_train, lowest_allowed_freq=1, tokenizer=tweet_tokenize)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    %time full_corpora_word_roberta_embedding = create_tf_embedding_lookup_on_text_vocab(full_roberta_train_vocab, roberta_tokenizer, roberta_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    full_train_roberta_embedding, full_train_roberta_vocab = create_tf_embedding(full_roberta_train_vocab, full_corpora_word_roberta_embedding)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# trying this model to get a ballpark for its performance\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    full_exp_roberta_embedding_color_input_mod = ExpColorizedInputDescriber(\n",
    "        vocab=full_train_roberta_vocab,\n",
    "        embedding=full_train_roberta_embedding,\n",
    "        encoder_hidden_dim=256,\n",
    "        decoder_hidden_dim=256,\n",
    "        early_stopping=True)\n",
    "\n",
    "    _ = full_exp_roberta_embedding_color_input_mod.fit(full_cols_train, full_seqs_train)\n",
    "\n",
    "    print(\"listener_accuracy:\\n\", full_exp_roberta_embedding_color_input_mod.listener_accuracy(full_cols_test, full_seqs_test))\n",
    "    print(\"bleu:\\n\", full_exp_roberta_embedding_color_input_mod.corpus_bleu(full_cols_test, full_seqs_test)[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Scores:\n",
    "**_Default settings + hidden_dim (256, 256) + 2 hidden layers, 0.8 dropout, unidirectional 0.856, 0.458_**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 9. Trying different hidden dims for encoder and decoder (Improvement on the Experimental Model above)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "\n",
    "    class VarColorContextDecoder(ColorContextDecoder):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "\n",
    "            self.rnn = nn.LSTM(\n",
    "                input_size=self.embed_dim + self.color_dim,\n",
    "                hidden_size=self.hidden_dim,\n",
    "                num_layers=2,\n",
    "                batch_first=True,\n",
    "                dropout=0.5,\n",
    "                bidirectional=False\n",
    "            )\n",
    "            self.output_layer = nn.Linear((int(self.rnn.bidirectional) + 1) * self.hidden_dim, self.vocab_size)\n",
    "\n",
    "    class VarEncoder(Encoder):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "\n",
    "            self.rnn = nn.LSTM(\n",
    "                input_size=self.color_dim,\n",
    "                hidden_size=self.hidden_dim,\n",
    "                num_layers=2,\n",
    "                batch_first=True,\n",
    "                dropout=0.5,\n",
    "                bidirectional=False\n",
    "            )\n",
    "\n",
    "    class VarColorizedEncoderDecoder(ColorizedEncoderDecoder):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "\n",
    "            # Adapters\n",
    "            self.encoder_decoder_adapter_h = nn.Linear(self.encoder.hidden_dim, self.decoder.hidden_dim)\n",
    "            self.adapter_activation_h = nn.ReLU()\n",
    "            self.dropout_h = nn.Dropout(p=0.5)\n",
    "\n",
    "            self.encoder_decoder_adapter_c = nn.Linear(self.encoder.hidden_dim, self.decoder.hidden_dim)\n",
    "            self.adapter_activation_c = nn.ReLU()\n",
    "            self.dropout_c = nn.Dropout(p=0.5)\n",
    "\n",
    "        def forward(self,\n",
    "            color_seqs,\n",
    "            word_seqs,\n",
    "            seq_lengths=None,\n",
    "            hidden=None,\n",
    "            targets=None):\n",
    "\n",
    "            if hidden is None:\n",
    "                hidden = self.encoder(color_seqs)\n",
    "\n",
    "            if hidden[0].shape[2] != self.decoder.hidden_dim:\n",
    "                hidden_h = self.dropout_h(self.adapter_activation_h(self.encoder_decoder_adapter_h(hidden[0])))\n",
    "                hidden_c = self.dropout_c(self.adapter_activation_c(self.encoder_decoder_adapter_c(hidden[1])))\n",
    "                hidden = (hidden_h, hidden_c)\n",
    "\n",
    "            # color_seqs -> (m, 3, color_dim)\n",
    "            target_color_seq = color_seqs[:, 2, :] # -> (m, 1, color_dim)\n",
    "            target_color_seq = torch.squeeze(target_color_seq, dim=1) # -> (m, color_dim)\n",
    "\n",
    "            output, hidden = self.decoder(\n",
    "                word_seqs, seq_lengths=seq_lengths, hidden=hidden, target_colors=target_color_seq)\n",
    "\n",
    "            if self.training:\n",
    "                return output\n",
    "            else:\n",
    "                return output, hidden\n",
    "\n",
    "\n",
    "    class VarColorizedInputDescriber(ColorizedInputDescriber):\n",
    "        def __init__(self, encoder_hidden_dim=50, decoder_hidden_dim=50, *args, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "            self.encoder_hidden_dim = encoder_hidden_dim\n",
    "            self.decoder_hidden_dim = decoder_hidden_dim\n",
    "\n",
    "            # to easily find if self.hidden_dim is being used elsewhere\n",
    "            self.hidden_dim = 0\n",
    "            self.params += ['encoder_hidden_dim', 'decoder_hidden_dim']\n",
    "\n",
    "        def build_graph(self):\n",
    "            encoder = VarEncoder(\n",
    "                color_dim=self.color_dim,\n",
    "                hidden_dim=self.encoder_hidden_dim\n",
    "            )\n",
    "\n",
    "            decoder = VarColorContextDecoder(\n",
    "                color_dim=self.color_dim,\n",
    "                vocab_size=self.vocab_size,\n",
    "                embed_dim=self.embed_dim,\n",
    "                embedding=self.embedding,\n",
    "                hidden_dim=self.decoder_hidden_dim,\n",
    "                freeze_embedding=self.freeze_embedding\n",
    "            )\n",
    "\n",
    "            return VarColorizedEncoderDecoder(encoder, decoder)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished epoch 1000 of 1000; error is 0.11831463128328323"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test result:\n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    print(\"Test result:\\n\", test_exp_full_system(VarColorizedInputDescriber))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# trying this model to get a ballpark for its performance\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    full_var_bert_embedding_color_input_mod = VarColorizedInputDescriber(\n",
    "        vocab=full_train_bert_vocab,\n",
    "        embedding=full_train_bert_embedding,\n",
    "        encoder_hidden_dim=32,\n",
    "        decoder_hidden_dim=256,\n",
    "        early_stopping=True)\n",
    "\n",
    "    _ = full_var_bert_embedding_color_input_mod.fit(full_cols_train, full_seqs_train)\n",
    "\n",
    "    print(\"listener_accuracy:\\n\", full_var_bert_embedding_color_input_mod.listener_accuracy(full_cols_test, full_seqs_test))\n",
    "    print(\"bleu:\\n\", full_var_bert_embedding_color_input_mod.corpus_bleu(full_cols_test, full_seqs_test)[0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Scores:\n",
    "default + 1 hidden_layer, 0 dropout, no adapter dropout, unidirectional, hidden_dim(32, 256)-> 0.851, 0.4299\n",
    "**_default + 1 hidden_layer, 0 dropout, 0.5 adapter dropout, unidirectional, hidden_dim(32, 256)-> 0.859, 0.433_**\n",
    "default + 1 hidden_layer, 0 dropout, 0.8 adapter dropout, unidirectional, hidden_dim(32, 256)-> 0.852, 0.434\n",
    "default + 1 hidden_layer, 0 dropout, 0.2 adapter dropout, unidirectional, hidden_dim(32, 256)-> 0.8586, 0.446\n",
    "default + 1 hidden_layer, 0 dropout, 0.5 adapter dropout, unidirectional, hidden_dim(32, 512)->0.855, x\n",
    "default + 1 hidden_layer, 0 dropout, 0.5 adapter dropout, unidirectional, hidden_dim(64, 256)-><similar to before> 0.857, 0.44\n",
    "**_default + 2 hidden_layer, 0.2 dropout, 0.5 adapter dropout, unidirectional, hidden_dim(32, 256)->0.8594, 0.431_**\n",
    "**_default + 2 hidden_layer, 0.5 dropout, 0.5 adapter dropout, unidirectional, hidden_dim(32, 256)->0.86152, 0.4432\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# testing roberta on this\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    full_var_roberta_embedding_color_input_mod = VarColorizedInputDescriber(\n",
    "        vocab=full_train_roberta_vocab,\n",
    "        embedding=full_train_roberta_embedding,\n",
    "        encoder_hidden_dim=32,\n",
    "        decoder_hidden_dim=256,\n",
    "        early_stopping=True)\n",
    "\n",
    "    _ = full_var_roberta_embedding_color_input_mod.fit(full_cols_train, full_seqs_train)\n",
    "\n",
    "    print(\"listener_accuracy:\\n\", full_var_roberta_embedding_color_input_mod.listener_accuracy(full_cols_test, full_seqs_test))\n",
    "    print(\"bleu:\\n\", full_var_roberta_embedding_color_input_mod.corpus_bleu(full_cols_test, full_seqs_test)[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**_Score on similar RoBERTa setup: 0.85998, 0.44581 (hidden_dim 32, 512)_**\n",
    "on a hidden_dim (32, 256) the score is: 0.8531, 0.4173"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 10. Super-sample the dataset (swap 1st and 2nd colors and keep the target text the same)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    # full_rawcols, full_texts = zip(*[[ex.colors, ex.contents] for ex in full_examples])\n",
    "    new_full_rawcols = [[colors[1], colors[0], colors[2]] for colors in full_rawcols]\n",
    "    new_full_texts = full_texts\n",
    "    sup_full_rawcols = full_rawcols + tuple(new_full_rawcols)\n",
    "    sup_full_texts = full_texts + new_full_texts\n",
    "\n",
    "    sup_full_rawcols_train, sup_full_rawcols_test, sup_full_texts_train, sup_full_texts_test = \\\n",
    "    train_test_split(sup_full_rawcols, sup_full_texts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    sup_full_seqs_train = [full_tokenize_example(s) for s in sup_full_texts_train]\n",
    "    sup_full_seqs_test = [full_tokenize_example(s) for s in sup_full_texts_test]\n",
    "    sup_full_cols_train = [represent_color_context(colors) for colors in sup_full_rawcols_train]\n",
    "    sup_full_cols_test = [represent_color_context(colors) for colors in sup_full_rawcols_test]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# the super sampled dataset has the same texts (with interchanged disturbances). So the vocab and the embeddings should remain the same\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    sup_full_var_bert_embedding_color_input_mod = VarColorizedInputDescriber(\n",
    "        vocab=full_train_bert_vocab,\n",
    "        embedding=full_train_bert_embedding,\n",
    "        encoder_hidden_dim=32,\n",
    "        decoder_hidden_dim=256,\n",
    "        early_stopping=True)\n",
    "\n",
    "    _ = sup_full_var_bert_embedding_color_input_mod.fit(sup_full_cols_train, sup_full_seqs_train)\n",
    "\n",
    "    print(\"listener_accuracy:\\n\", sup_full_var_bert_embedding_color_input_mod.listener_accuracy(sup_full_cols_test, sup_full_seqs_test))\n",
    "    print(\"bleu:\\n\", sup_full_var_bert_embedding_color_input_mod.corpus_bleu(sup_full_cols_test, sup_full_seqs_test)[0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    torch.save(sup_full_var_bert_embedding_color_input_mod, os.path.join(\"data\", \"colors\", \"sup_full_var_bert_embedding_color_input_mod.mod\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# trying this on RoBERTa\n",
    "# the super sampled dataset has the same texts (with interchanged disturbances). So the vocab and the embeddings should remain the same\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    sup_full_var_roberta_embedding_color_input_mod = VarColorizedInputDescriber(\n",
    "        vocab=full_train_roberta_vocab,\n",
    "        embedding=full_train_roberta_embedding,\n",
    "        encoder_hidden_dim=32,\n",
    "        decoder_hidden_dim=512,\n",
    "        early_stopping=True)\n",
    "\n",
    "    _ = sup_full_var_roberta_embedding_color_input_mod.fit(sup_full_cols_train, sup_full_seqs_train)\n",
    "\n",
    "    print(\"listener_accuracy:\\n\", sup_full_var_roberta_embedding_color_input_mod.listener_accuracy(sup_full_cols_test, sup_full_seqs_test))\n",
    "    print(\"bleu:\\n\", sup_full_var_roberta_embedding_color_input_mod.corpus_bleu(sup_full_cols_test, sup_full_seqs_test)[0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    torch.save(sup_full_var_roberta_embedding_color_input_mod, os.path.join(\"data\", \"colors\", \"sup_full_var_roberta_embedding_color_input_mod.mod\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**_Best model so far (BERT Embedding based), score: 0.9172, 0.453_**\n",
    "**_Better one. (RoBERTa Embedding based), score: 0.9264, 0.4671_**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_original_system(trained_model, color_seqs_test, texts_test):\n",
    "\n",
    "    tok_seqs = [full_tokenize_example(s) for s in texts_test]\n",
    "\n",
    "    col_seqs = [represent_color_context(colors)\n",
    "                for colors in color_seqs_test]\n",
    "\n",
    "    evaluation = trained_model.evaluate(col_seqs, tok_seqs)\n",
    "\n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\My Drive\\MLDL\\stanfordXCS224U\\referenceRepo\\cs224u\\torch_color_describer.py:680: RuntimeWarning: divide by zero encountered in power\n",
      "  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n"
     ]
    }
   ],
   "source": [
    "my_evaluation = evaluate_original_system(sup_full_var_roberta_embedding_color_input_mod, sup_full_rawcols_test, sup_full_texts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.9261607864833808"
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_evaluation['listener_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.46715179883476743"
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_evaluation['corpus_bleu']"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test results (ran on online judge):\n",
    "**_'listener_accuracy': 0.9030034465780404, 'corpus_bleu': 0.6912203345869538_**\n",
    "\n",
    "**_Avg accuracy for humans to correctly identify the colors based on the description generated by other humans ( in the SCC dataset) is 90%_**\n",
    "This model is at par with an experimental human performance."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Future Work\n",
    "1. Reducing the vocab to include only effective tokens actually improves the english outputs. Since the accuracy did not improve much,\n",
    "we did not proceed with that in the final pipeline. But including this might lead to a good bleu score along with a decent listener_accuracy.\n",
    "2. We can train the ColorDescriber by keeping it on a neural conversation with a neural listener (that replies back too). The dataset supports\n",
    "2-way conversation\n",
    "3. We can pursue an ensemble of various good-performing models above by combining their probability distributions.\n",
    "4. We can try character-level tokenization and representation too."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### References\n",
    "\n",
    "1. [Monroe et. al. 2016](https://nlp.stanford.edu/pubs/monroe2016color.pdf)\n",
    "2. [Monroe et. al. 2017](https://transacl.org/ojs/index.php/tacl/article/view/1142)\n",
    "3. [Prof. Chris Potts' NLP Research Architecture](https://github.com/cgpotts/cs224u)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}